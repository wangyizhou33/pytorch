{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a048add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fea9e1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of caracters and mappings to/from intergers  \n",
    "words = open('names.txt','r').read().splitlines()\n",
    "\n",
    "chars = sorted(set(\"\".join(words)))\n",
    "stoi  = {s:i for i,s in enumerate(chars, start=1)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04240a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# split the dataset to \"training\", \"validation\" and \"test\"\n",
    "\n",
    "\n",
    "# build the dataset \n",
    "block_size = 3  # context length, we take 'e','m','m' to predict 'a'\n",
    "\n",
    "def build_dataset(words):\n",
    "    X,Y = [],[]\n",
    "\n",
    "    for w in words: \n",
    "        context = [0] * block_size # pre-pend empty char\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix]\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X,Y\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5d0f30e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11897\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "n_embd = 10\n",
    "n_hidden = 200\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd),             generator=g)    # one char to 2 features, feature layer\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g)  # hidden layer\n",
    "b1 = torch.randn(n_hidden,                        generator=g)    \n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g)# output layer\n",
    "b2 = torch.randn(vocab_size,                      generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "print(sum(p.nelement() for p in parameters))  # total number of parameters\n",
    "\n",
    "\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0de6e684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 27.8817\n",
      "  10000/ 200000: 2.6480\n",
      "  20000/ 200000: 2.5211\n",
      "  30000/ 200000: 2.8322\n",
      "  40000/ 200000: 2.1849\n",
      "  50000/ 200000: 2.5281\n",
      "  60000/ 200000: 2.4177\n",
      "  70000/ 200000: 2.0097\n",
      "  80000/ 200000: 2.2562\n",
      "  90000/ 200000: 2.1336\n",
      " 100000/ 200000: 2.0161\n",
      " 110000/ 200000: 2.4205\n",
      " 120000/ 200000: 1.8736\n",
      " 130000/ 200000: 2.3686\n",
      " 140000/ 200000: 2.2255\n",
      " 150000/ 200000: 2.1092\n",
      " 160000/ 200000: 1.9994\n",
      " 170000/ 200000: 1.7841\n",
      " 180000/ 200000: 1.9813\n",
      " 190000/ 200000: 1.7708\n"
     ]
    }
   ],
   "source": [
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # mini-batch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]  # batch X,Y\n",
    "    \n",
    "    # forward pass\n",
    "    emb = C[Xb]  # (32, 3, 2)\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    h = torch.tanh(embcat @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, Yb)\n",
    "    # backward \n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")\n",
    "    lossi.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ef6ce78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fba1b277100>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA7e0lEQVR4nO3deXhU5f3+8XsSskIWQsgGYd9kFVACVRCFskjd+1XRX6vW4lLcSlWKG1pbodqK1SK1VkVrEbVV3BBlXwNIJOwEEhLClrCEZEL2ZJ7fH4ExQwIkkHgmOe/Xdc11Zc555pzPMyeZc+cszziMMUYAAAAW8bG6AAAAYG+EEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApZpZXcDpXC6XDh48qJCQEDkcDqvLAQAAtWCMUX5+vuLi4uTjU7djHV4XRg4ePKj4+HirywAAAOdh3759atu2bZ1e43VhJCQkRFJlZ0JDQy2uBgAA1IbT6VR8fLx7P14XXhdGTp2aCQ0NJYwAANDInM8lFlzACgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClvO6L8hrK0RMlmrk0VYF+vpo8pofV5QAAgJNsc2TEWVSmd1Zn6D9r91pdCgAAqMI2YQQAAHgnwggAALAUYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKVsF0aM1QUAAAAPtgkjDofD6hIAAEANbBNGAACAdyKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwlP3CCAONAADgVewXRgAAgFexTRhhyDMAALyTbcIIAADwToQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWsl0YYcwzAAC8i+3CCAAA8C62CSMORj0DAMAr2SaMAAAA70QYAQAAliKMAAAASxFGAACApQgjAADAUnUKI9OmTdOll16qkJAQRUVF6frrr1dKSopHm+HDh8vhcHg87rvvvnotGgAANB11CiPLly/XxIkTtXbtWi1cuFBlZWUaNWqUCgoKPNpNmDBBhw4dcj9efPHFei36QhjDsGcAAHiTZnVpvGDBAo/ns2fPVlRUlJKSkjRs2DD39ODgYMXExNRPhQAAoEm7oGtG8vLyJEkREREe0//zn/8oMjJSvXv31pQpU1RYWHjGZZSUlMjpdHo8GoJDjHoGAIA3qtORkapcLpceeeQRXXbZZerdu7d7+m233ab27dsrLi5Omzdv1uTJk5WSkqJPPvmkxuVMmzZNzz333PmWAQAAGrnzDiMTJ07U1q1btWrVKo/p99xzj/vnPn36KDY2ViNGjFBaWpo6d+5cbTlTpkzRpEmT3M+dTqfi4+PPtywAANDInFcYeeCBB/Tll19qxYoVatu27VnbJiQkSJJSU1NrDCMBAQEKCAg4nzIAAEATUKcwYozRgw8+qE8//VTLli1Tx44dz/ma5ORkSVJsbOx5FQgAAJq2OoWRiRMnas6cOfrss88UEhKirKwsSVJYWJiCgoKUlpamOXPm6Oqrr1arVq20efNm/fa3v9WwYcPUt2/fBukAAABo3OoURmbNmiWpcmCzqt555x3deeed8vf316JFi/TKK6+ooKBA8fHxuummm/TUU0/VW8EAAKBpqfNpmrOJj4/X8uXLL6ighsaQZwAAeBe+mwYAAFjKNmHEwZhnAAB4JduEEQAA4J0IIwAAwFKEEQAAYCnCCAAAsBRhBAAAWMp2YeQcQ6UAAIAfme3CCAAA8C6EEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApWwXRowY9QwAAG9iuzACAAC8C2EEAABYyjZhxOGwugIAAFAT24QRAADgnQgjAADAUoQRAABgKcIIAACwFGEEAABYynZhxDDmGQAAXsV2YQQAAHgXwggAALCUbcKIg1HPAADwSrYJIwAAwDsRRgAAgKUIIwAAwFKEEQAAYCnCCAAAsJTtwghjngEA4F1sF0YAAIB3IYwAAABL2SaMMOQZAADeyTZhBAAAeCfCCAAAsBRhBAAAWIowAgAALGW/MMJAIwAAeBX7hREAAOBVCCMAAMBShBEAAGAp24QRB6OeAQDglWwTRgAAgHcijAAAAEsRRgAAgKUIIwAAwFK2CyOGUc8AAPAqdQoj06ZN06WXXqqQkBBFRUXp+uuvV0pKikeb4uJiTZw4Ua1atVKLFi100003KTs7u16LBgAATUedwsjy5cs1ceJErV27VgsXLlRZWZlGjRqlgoICd5vf/va3+uKLL/Txxx9r+fLlOnjwoG688cZ6LxwAADQNzerSeMGCBR7PZ8+eraioKCUlJWnYsGHKy8vTW2+9pTlz5uiqq66SJL3zzju66KKLtHbtWg0ePLj+KgcAAE3CBV0zkpeXJ0mKiIiQJCUlJamsrEwjR450t+nRo4fatWunxMTEGpdRUlIip9Pp8QAAAPZx3mHE5XLpkUce0WWXXabevXtLkrKysuTv76/w8HCPttHR0crKyqpxOdOmTVNYWJj7ER8ff74lnZVDDMEKAIA3Ou8wMnHiRG3dulVz5869oAKmTJmivLw892Pfvn0XtDwAANC41OmakVMeeOABffnll1qxYoXatm3rnh4TE6PS0lLl5uZ6HB3Jzs5WTExMjcsKCAhQQEDA+ZQBAACagDodGTHG6IEHHtCnn36qJUuWqGPHjh7zBw4cKD8/Py1evNg9LSUlRZmZmRoyZEj9VAwAAJqUOh0ZmThxoubMmaPPPvtMISEh7utAwsLCFBQUpLCwMN19992aNGmSIiIiFBoaqgcffFBDhgzxmjtpDGOeAQDgVeoURmbNmiVJGj58uMf0d955R3feeackacaMGfLx8dFNN92kkpISjR49Wq+//nq9FAsAAJqeOoURU4vDCoGBgZo5c6Zmzpx53kUBAAD7sN130wAAAO9CGAEAAJayTRhxMOYZAABeyTZhBAAAeCfCCAAAsBRhBAAAWMp2YYQxzwAA8C62CyMAAMC7EEYAAIClCCMAAMBShBEAAGAp24QRxjwDAMA72SaMAAAA70QYAQAAlrJdGDGGkUYAAPAmtgsjAADAuxBGAACApQgjAADAUoQRAABgKcIIAACwlH3CCKOeAQDglewTRgAAgFcijAAAAEvZLoww5BkAAN7FdmEEAAB4F8IIAACwFGEEAABYijACAAAsRRgBAACWsk0YcTDqGQAAXsk2YQQAAHgnwggAALCU7cKIYdQzAAC8iu3CCAAA8C6EEQAAYCnCCAAAsBRhBAAAWIowAgAALGWbMOJgzDMAALySbcIIAADwToQRAABgKcIIAACwFGEEAABYijACAAAsRRgBAACWIowAAABL2TKMHMorsroEAABwkm3CSNUxz/KKyiyrAwAAeLJNGAEAAN6JMAIAACxlyzBijNUVAACAU2wZRgAAgPeocxhZsWKFrrnmGsXFxcnhcGjevHke8++88045HA6Px5gxY+qrXgAA0MTUOYwUFBSoX79+mjlz5hnbjBkzRocOHXI/PvjggwsqEgAANF3N6vqCsWPHauzYsWdtExAQoJiYmPMuCgAA2EeDXDOybNkyRUVFqXv37rr//vt17NixM7YtKSmR0+n0eAAAAPuo9zAyZswYvffee1q8eLH+/Oc/a/ny5Ro7dqwqKipqbD9t2jSFhYW5H/Hx8fVdkiTJ4XBU+blBVgEAAM5DnU/TnMutt97q/rlPnz7q27evOnfurGXLlmnEiBHV2k+ZMkWTJk1yP3c6nQ0WSAAAgPdp8Ft7O3XqpMjISKWmptY4PyAgQKGhoR6PhsY4IwAAeI8GDyP79+/XsWPHFBsb29CrAgAAjVCdT9OcOHHC4yhHenq6kpOTFRERoYiICD333HO66aabFBMTo7S0ND3++OPq0qWLRo8eXa+FAwCApqHOYWTDhg268sor3c9PXe9xxx13aNasWdq8ebPeffdd5ebmKi4uTqNGjdLzzz+vgICA+qsaAAA0GXUOI8OHD5c5y0UX33zzzQUVBAAA7MU2301ztgAFAACsY5swAgAAvJNtwoiDkc4AAPBKtgkjAADAO9kyjHD5CAAA3sOWYQQAAHgPwggAALAUYQQAAFjKNmGEcUYAAPBOtgkjAADAOxFGAACApWwTRhj0DAAA72SbMFIVuQQAAO9hyzDCtawAAHgPW4YRAADgPQgjAADAUrYJI4wzAgCAd7JNGAEAAN6JMAIAACxFGAEAAJayTRhh0DMAALyTbcIIAADwTrYMI0bcWQMAgLewZRgBAADegzACAAAsZZswwqBnAAB4J9uEEQAA4J0IIwAAwFKEEQAAYCnbhBEGPQMAwDvZJowAAADvRBgBAACWIowAAABL2SaMMM4IAADeyTZhBAAAeCdbhpHyCo6SAADgLWwZRt5fu9fqEgAAwEm2DCNbDzqtLgEAAJxkmzDCoGcAAHgn24QRAADgnWwZRrjNFwAA72HLMAIAALyHbcIIR0MAAPBOtgkjAADAOxFGAACApQgjAADAUrYMI6UVLqtLAAAAJ9kmjFQd9GzPkQILKwEAAFXZJowAAADvRBgBAACWsk0YYZwRAAC8k23CCAAA8E51DiMrVqzQNddco7i4ODkcDs2bN89jvjFGzzzzjGJjYxUUFKSRI0dq9+7d9VUvAABoYuocRgoKCtSvXz/NnDmzxvkvvviiXn31Vf3jH//QunXr1Lx5c40ePVrFxcUXXCwAAGh6mtX1BWPHjtXYsWNrnGeM0SuvvKKnnnpK1113nSTpvffeU3R0tObNm6dbb731wqoFAABNTr1eM5Kenq6srCyNHDnSPS0sLEwJCQlKTEysz1UBAIAmos5HRs4mKytLkhQdHe0xPTo62j3vdCUlJSopKXE/dzqd9VmSW9VBzwAAgPew/G6aadOmKSwszP2Ij4+3uiQAAPAjqtcwEhMTI0nKzs72mJ6dne2ed7opU6YoLy/P/di3b199luTGOCMAAHineg0jHTt2VExMjBYvXuye5nQ6tW7dOg0ZMqTG1wQEBCg0NNTjAQAA7KPO14ycOHFCqamp7ufp6elKTk5WRESE2rVrp0ceeUR//OMf1bVrV3Xs2FFPP/204uLidP3119dn3QAAoImocxjZsGGDrrzySvfzSZMmSZLuuOMOzZ49W48//rgKCgp0zz33KDc3V5dffrkWLFigwMDA+qsaAAA0GQ7jZRdTOJ1OhYWFKS8vr15P2Rw7UaKBf1zkfp4xfVy9LRsAALu7kP235XfTAAAAeyOMAAAAS9kmjDDoGQAA3sk2YQQAAHgn24QRL7tOFwAAnGSbMAIAALwTYQQAAFiKMAIAACxFGAEAAJYijAAAAEsRRgAAgKVsE0YY9AwAAO9kmzACAAC8E2EEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClCCMAAMBStg0jxhirSwAAALJRGDl9yLMlOw9bUgcAAPBkmzByuqS9x60uAQAAyMZhBAAAeAfCCAAAsJRtwwjfmwcAgHewbRgBAADewbZhxFHt/hoAAGAF24aRzQfyrC4BAADIxmHkaH6J1SUAAADZKIyEBfl5PN9+yGlRJQAAoCrbhBEfn+rXiGzZz6kaAACsZpswUpOjBZyqAQDAarYOIwAAwHqEEQAAYClbhxFGGgEAwHq2DiMAAMB6hBEAAGApW4cRB9+WBwCA5WwdRgAAgPUIIwAAwFK2DiOcpAEAwHq2DiMAAMB6hBEAAGApW4cRbqYBAMB6tg4jAADAerYOI8ZYXQEAALB1GKlwkUYAALCarcPIl5sPWV0CAAC2Z+swkldUZnUJAADYnq3DSGZOgdUlAABge7YOI7uyT1hdAgAAtmfrMAIAAKxHGAEAAJaq9zDy7LPPyuFweDx69OhR36sBAABNRLOGWGivXr20aNGiH1bSrEFWAwAAmoAGSQnNmjVTTExMQywaAAA0MQ1yzcju3bsVFxenTp066fbbb1dmZuYZ25aUlMjpdHo8fkzlFa4fdX0AAMBTvYeRhIQEzZ49WwsWLNCsWbOUnp6uoUOHKj8/v8b206ZNU1hYmPsRHx9f3yWd1evL0n7U9QEAAE8OYxr26+Jyc3PVvn17vfzyy7r77rurzS8pKVFJSYn7udPpVHx8vPLy8hQaGlqvtXT4/Vc1Ts+YPq5e1wMAgN04nU6FhYWd1/67wa8sDQ8PV7du3ZSamlrj/ICAAAUEBDR0GQAAwEs1+DgjJ06cUFpammJjYxt6Veftb4t2W10CAAC2Ve9h5NFHH9Xy5cuVkZGhNWvW6IYbbpCvr6/Gjx9f36uqNzMW7XL/vP94oYrLKiysBgAAe6n30zT79+/X+PHjdezYMbVu3VqXX3651q5dq9atW9f3qurdjkNOjf3bSrUJD9Lq319ldTkAANhCvYeRuXPn1vcifzRj/7ZSknQgt+iMbfKLy/TaklRd0zdOfdqG/VilAQDQZPHdNCftyymsVbsXF6Tonyv26Jq/r2rgigAAsAfCyElDX1xaq3YpWTWPlwIAAM4PYeQs0o8WqKCk3HOiw5paAABoqvgGuzO47c21WpN2TK2a+yvp6Z+6p/sQRgAAqFccGTmDNWnHJEnHCko9pvs4SCMAANQnwkgdkUUAAKhfnKaphQfmfK9gf199tGG/QgJ/eMv2HDmh15el6TfDO6tT6xYNsm6Xy6jM5VJAM98GWT4AAFYjjNTCl5sPuX/OL/7hgtbb/7VOh/KKtWLXES17bLiC/ev/7bz5jURt3Jer75/+qcKC/Op9+QAAWI3TNBfgUF6xJOlwfol6PvONjp0oOccr6m7D3uOqcBmt3H2k3pcN/JjyCss09m8r9fqymr80E4B92SqMtAxu2CMLy3fVHBiMMXr+y+16d03GeS+bC2fR2L25co92HHLqxQUpVpcCwMvYKoz8fGDbBl3+W6vStWRntvv5qTFKvt2erbdWpWvq59vOe9k5BaUqLXddcI01yS0slTHmjPMLS8vPOO/H5nKduc7T232WfEDpRwsauCJ7ONvvR22VlPMFlABqZqsw8uuhnRp0+dsOOvWr2Ru0cvcRzVyaql5Tv9Ftb67Vvf9O8mhXXuFStrPY/by4rEIFJeXKLSw9fZFuT83bqm5Pfa0vNh2s15rfXZOhi/+wUB2nzK9x/sbM4+r5zDd68tMt9bremry4YKee+WzrGeevST2qXlO/0X+T9kuqDGjPfr5N2w7mVWv7xeaDenhusq78yzKP6XmFZTqSX/+n0y6EMabevim6rKL+A+uGjBxd+qdFF/y7Vw95BkATZasLWH+sC0B/8dZ698+nxis55cUFO/X6sjRJ0tx7BuvA8SL97uNNP7x2cHs9d20vZRwr0F2zv6u27Ac/2Ki9xwr04YZ9uj2hve67onO1NvuPFyozp1D92obrQG6RukWHnLHWcx2t+dvi3ZKk/6zLVHGZS1Ou7qHIFgHV2iWmHdPq1KMK9PNRUVmFHhvdw2N+cVmFMnMKz1hLeYXL/b6EBDbTld2j1Ll1C7Vs7u9uc/e7G1RUVqFHP96knw9sqyc/3aKvt2Zp9poMZUwfpy3782Rk1LdtuDZkHK9xPf3+8K0kadtzo9U8wPPX/2BukZalHNE1/WIlSdsPOtWpdQu1Dqne3/p0//vfa8G2LK18/ErFRwSf93L+tmi3Xlm8S59PvLzalzgaY5R2pECdIpvL5ywj91W4jHxPm3/3uxuUV1SmBz/YqDG9Y7Rq91EN7NBSoYF1+3siiwA4E1uFkUA/62+PPbXDlaRb/7m22vx/r92rD7/bp9Kz/If7l293SZKmf71Tgzu10sXx4SqrcMlljHwdDl3+Z8/v2Znz6wTNXpOhTq1b6Pdje8jlMnI4JEcN16FsPZCn8f9cq+v6x+mZn/XSspQfroP53/f79b/v9+uyLq30/t0JWr7riHrGhSoqJFDj3/Tsy20J7dUmPEgHcov08AcbtWFvZTh4/fYBurpP7Fnfo5lL0zRzaZrCg/2U/MwoFZdV6Pkvt6votKMHOw453T8Xl1W4v7xwxx/GeLRbn56j/u3C5ef7w4HAfccL1SMm1KPdmFdWyFlcrieqHAXy83Vo4zOj1MzHcc7fn5LyCr3w1Q5ddVG0rujW+qxtT532cDgcWrAtS5I0+X+bNWfC4LO+7mxmLKr8vXj+y+366L4hHvMe+TBZnyVXHtn44/W99dGGfXrnzkvVqkqwfC8xQy/M36E5EwZrQLuW7ukVVU6NzVyaqlcW7VafNmH64sHLa6zjeEGpwoP9avz9AoCa2CqMNBZnCyKnu37mao/n3aKrj3fy3BfblZKdLylbWXlFmpd8UHFhgZpy9UUe7X77YbI+3XhAkvT+2kx9trHmw/KrU4/pln+u1fr0HEnSjFv6VWuTdviEVu8+qnfWZHiEhrnf7dPY3jFyOBzae6xAV7y0TH/9v3667uK4asvILSyTVHktzn/WZXrM23usQBnHfvimZWdRmfvn9Rk5Hm1vfiNRt1wSr4EdftjBbsg4Xi2MOIurXxtTVmHUe+o3kqQOrYI1uleMbr40Xk98skV3XdZRY3rHSKq8RmX26gy9m7hX7ybuVcb0ce5lHMwtUmxYoMfO+d5/J2nf8SJ98cBl7mlr0o4p21ms6NBA97TtB51q0zJIIQHN1OmJylNpaS9cXe3oRVVVM0B+cZlCAv3cQUSqPOUnSa8s2q3nr+/tnv7MZ5VHyW58fY3GD2qnD9ZnakinVh7XKr2yqPJI2ZYDeVqaclhdWrfQr9/doLsv76ghnVtpyidbtCr1qG5PaKc/3dDH/bryCpfHaZpN+3LVLz78jH3AD8orXCoud6lFgD0+ritcRpv356p3mzD3PxCZxwr19dZDun1w+2rvw8HcIsWEBp71iJ83KSqt0JKdhzW0W2Sdjy42ZQ5TH1em1SOn06mwsDDl5eUpNDT03C+oow6//6rel4m6mzymh/68YKf7+Xu/GqRfvr2+WrseMSHaeR7flFyb1+18fozH0Y7z+d24cUAb+TocWp+Ro71VwtHnD1ymvm3D9eF3mZr8vy0a2ztGs/7fQBWUlMvhkHo+Uxlw/nf/EN00K9H9uuev66WxfWK1ISNHkz7apMLSyqNBnVo3154jlRfjTr2mp67pF6fIFgHaf7xQT366VTGhgfpwwz5J0uBOEXr55ou1MTNXE+d8r86tmyvtSPULecf1idUT4y5Sm/Cg8+7/2WRMH6fZq9P17Bfbq83rFReqrx4ael7LLSmvUFmFaZCd86G8Ivn6OBQVEnjuxj+S0TNWKCU7X989ObJeThnWdCquLkrLXdpyIFfFZS4N7tTqnMsqLXfJv1ntLk9M3pfr/gfrhv5tNOOWiyVJFz29QEVlFRo/KF7Tbuzrbv/V5kOaOOd7XdsvTq+O739+HfqRPfrxJv03ab9+0rmVfjO8i9alH9MjI7td0DbxFhey/yaMAD+SU6et6suN/dvok5NHshqbc4WR5H25ig0L9DhKdEr/P3yr44Vl2vrcaLUIaKbyCpee+2K7vt2epdl3DdJFsef3uVFYWu4OiXteuLpW/2kbY6qdjjrsLNb+3CL1axteLzuYU59Zf/m/fu47AssrXHp18W4N7txKP+kcWetlTft6h/6duFcLHh6mdq3O7/qk3lO/0YmTdwrefElbvfjz6kdGT9mVna9RM1borss6aOo1vc657NM/nzOmj9Omfbm67mRA6RTZXEseHe6eP/ZvK91HXqsejfyx/PbDZC1NOazVk6+qdg3amdS0D3rx53118yXx51XDdxk52pBxXPcO61Sr39nScpeS9+Xq4vjwWofE2rqQ/bet7qYBrFSfQURSow0iUuWdZ68u3q2lOw+7r0mpcBmlHy3QI3M36vqZq5XwwmL95j+Vd6K5XEbbDzpV4TI6fvL03faDlTuhX727Qf9eu1fZzhJN+uiHi8GNqTzcf6Zb06v+H3aipFz/O3mXliSVu4zKK1x6c8UebT2QJ2OMu05ncZm2HczTJ9/vV7/nvtWi7dlamnJYeSfrGvTCYt34+hp1fmK+Xjt5AXhduVxGd8/+Tn/88oejSlX3M39fmqpXl6TqtjfX6URJuYwxynYWe5wSlaTd2fm69Z+JynYW64X5O/TG8j0qLK3Qg3M3asHWrPOq7VQQkaSPNlS+Z4edxRrzygq9l5ghqfLOt13Z+Xr55PVt76zOOK91SdLDcze6f95T5Vb9CpdR1V3v1gOVd9WVlrvOORyBs7jsggapNMYo81ihPt14QLmFZXp1yW499MFGrdp9tFrbbGexVqcedddck1W7j+rTjftV4TLKyivW4//dVONdgjX5v38k6s8LduqLzZWnYjfvz9Uby9NUfvJ0f9Le4/r7kt3u51M/36qb30jU1M/PfOeiFexxEhKA13l5YeWOamD7lrpxQBstTzmib7dne7SZvyVLC7dn68lPt+hwfoluGvDDWEHGGBWWlmtFlcEGdxxyqqS8Qlv252nP0QI9/t/N8nFIPWJCNWFYR7Vv1Vx92oTpsY83aVf2CX32wGV6c+WeagOxpR4+oV++vU5HT1Tebj+0a6R2Z5/QzNv7e5xWk6Rfv7dBktS5dXMt/t1wj3l/XbhLD47oKklK2pujzfvzdPMl8fp6a5YO5hbp5YW7FBUSoCWPDldpuUs5BSXqEhWipMzjWrzzsMeyTh2A2ZdT6L52R6o8UjG0a6RWntwRzvl1gtam56hz6+Z6eG6yJCnhhcUey9q0L1f3vZ+kx0Z3131XdJbPyQvaK1xG6/YcU9foEO3KzldCxwj95dtdOnqixH1L/ekO5xfrL9+maGdWvp75bJv6x7fUbf9aV61d0t4cDWjX8owXNtd0kP7zGm4nLy13ac66vZq+YKeKy364nulnr61yX+skVd4xt2l/rjKPFepAbpEm/bSbHA6Hissq1PfZyrvq+rcL1/PX9VbvNp53n2UcLVBRWYXWp+doYPuWCvTz1YmScjmLylRUVqG1e455BKw3lu9x1zv7rkvVMy5UEcH+OlZQ6n7vQwKaKb+k5pD0+aaD+nzTQZWUufT7TyovoP9ow35tfW60mvv76qG5yWoTHqRfDmmvZSlHlJlTqMljunu8l6mHTyjzWKGu/XvlUaRpX+9UxvRxumnWGklSaJCfxvSK0QfrK0/nfrB+n8cpL6txmgZAo9ShVbDHRcy1deOANvrk+8qjSndd1uGC/ms/3ZxfJ9S4I66Lx8d0P+MotTf0b6OyCpfH92XVl23Pjdb//SNR2087ulLf9rxwtY4Xlmrm0jS9vTpd4/rG6smrL9JPpi+p1/V0jw45eeF+pTG9Ytx3rp3Ov5mPSstdeuLqHsorKtPMpWk1trPCHUPa693EvdWm33VZB40f1E6jZqw442urhtSa1PepLa4ZqQPCCAAA3hVGuGYEAABYijACAAAsRRgBAACWIowAAABLEUYAAIClbBdGru1X/TtQAACAdWwXRi7r0srqEgAAQBW2CyMAAMC7EEYAAIClbBdGqn7DZcofx1hYCQAAkGz4RXnxEcFa/furFB7kp4BmvlaXAwCA7dnuyIgktQkPUvOAyhz22OjukqSuUS2sLAkAANuyZRipauKVXbR2ygg9cFWXc7Yd0yvmR6gIAAB7sd1pmprEhAVqSGfPW34D/Xz01UND1bl1Cx0vKFXL5v66//0k9/zrL47TiIuitfdYgfq0DdcV3VqrvMKl+Vuz9NAHGyVJ4we107CukXrm8226undMjV8DLUn+vj4qrXB5TFv5+JUK8vfVhowc3ff+97XqR5vwIEWFBmhjZu4Z2wxs31JJe4/XankAAPwYHMYYY3URVV3IVxBfqNzCUlW4jFbuPqqRPaPVIsAzq/1jeZqmf71T0tm/ejn1cL5aBPgpJiyw2jxjjA7kFunyPy+VJH354OWKCgnQv1ala866TJ0oKa+2/A+/y9Tk/21xP3/hhj564tPK5/de0Ul3DOmguPCgaus67CzW55sO6o9f7VCb8CCt/v1Vla+fv0P/XLGnVu9JTV6+uZ8O5RXrpW9SJEmPjuqmv3y766yvCfb3VWFpRY3z/n5bf43pFaNFO7IV7N9Mv3x7vWLDAlVS7lJOQam73YB24cotLFPbiGCt2HVEkjT9xj76/SdbalxuTZ69pqfeTdyr9KMFtX5NQ3poRFe9uni31WUAsKGz7cfOx4XsvwkjdVBa7tJ7iRka1q21ukWHXNCysvKKVe5yqW3LYPe0fTmFmv71Tk0Y1kkXx4d7tDfGaNGOwwoP9tOlHSLqtK6MowWKDQ90X7DrchlNeG+DOkQ219M/66nyCpeOnihV+tECjX9zrft1PWNDtf2QU5Lk5+tQWYXRhKEd9eS4nsorLNM1f1+lsb1j9NCIrrr330ka3TtGT8/bKknqFx+uTfty3ctKnHKVnv9yu+Zvyape32l/EOlHCxQbFihfH4e+y8jRbW+uU2QLfy19dLhCAv1q7OPWA3kqLqtQucvo1n+u1fDurXXP0E667V/rJHke6ZIqg+ebK/eoV1yYXl28Wzuz8j2Wd2P/Nvpk4wFJUkhAM13SoaWWphyptt5BHSP02vj+OlFSrjnrMjV+ULy6RIVoxF+XKe3IuQNPxvRx6vD7r9zPR/SI0uKdhyVJC387TM18fZRTUKr9xwu1Pj1Ht17aTv9cuUcThnbUtX9ffc7lfzBhsFanHtW7iRn6ac9offL9Afe8gGY++tcdl+gXb60/53JaNffXk+Mu0qSPNp2zrVQZsn/22ir386WPDtffFu3ST7pE6vH/bq7VMlB3w7q1dgd14FwII2fhzWHEDoa9uFSZOYXy83Vo95+uVk5BqcKD/LT/eJEW7cjW+EHtFORfGWqMMXI4HB6vP5xfrO0HnbqiW2sdyS9RgJ+vKlxGEc39VVJeofv+naTkfbmaN/Ey7co+oR4xIYqPCK6plPOWV1imkMBmSj9WoBF/XS6pdn90L3+boleXpEqSdj4/Rj2eXiBJ+u3Ibnp4ZFcVlJSrma9Dg19YrMLSCm15drT8m9V82dX+44X618p03X15Rw19cal7+u4/jdWcdZn6dOMBPX9db/VpG6bEtGPuEDi6V7S+2ZYtSdrw1EhFtgg4Y72fbzqob7dl6ZGRXfX+2kzdltBOH2/Yp5/2jNG7azLUITJYj43u4fGaWcvS9I/laXri6h76ac8YbTmQpzvergwjf7qht8Zf2k5TPtmiLzYf1F/+r5+WpxxRrzahuvmSeAX6/XD32c4sp5Izc/X7T7aoTXiQIkMC9IvB7bUx87iu799Gl3aIcIes/90/RAPb/xCgq4av85E+7Wrd+s+1Wpee4zF92o19NOWTLRrUIULrM36YVzVYStKKx67UsJeW6nQhgc30q8s66v7hnfVx0n5t2Z+rjzbslySl/mmsujz59Vnreu7aXpr6+TaPafMfGqqrX10pSRrevbWWVQm0f7v1Yv1j+R7tOBn4z8edP+mg2WsyJElz7xmswZ1aKdtZrIQXFrvb/LRntB4e0VXX/H2VesSE6qcXRbl/zyVp5m0DtDPLqdeqTJOkF3/et1pwHD+onW6+pK2ynSW6r8pp67Ytg3RD/zb618p0FZVV6O+39Zcxkq+PQ7/5z/fq1zZME6/son+tStf6k9vt7ss76q1V6dX69NBVXRQVGqgPv9una/rF6oX5O2vs+82XtNXoXjH654o9Wpeeo4tiQ6u9lzcNaCuHQ9q0L1fB/r5ymcqjtHMmDFbakRMaNWOFR/uwID/lFZWd6e32MLx7aw3t2lrPf7ndPa1nbKjuvaKTHp6bXKtltGrur9du66/b3qz8pyn1T2PVzLfyM+XUZ7EkdYlqodTDJ864nDbhQTqQW1Rt+rbnRiv9aIHWpecoMe2oFu047DGfMHIWhBFr7TlyQn9duEsPXNlFF8U2zPtfU4hpKP9L2q9WLfw1vHvUOduWlFfok+8PaGjXSLVtGawNGTlauD1bv/1pN48dcWm5Sy5jPKadzdKdh/XEp1s045aLNbhTzV9HcGoHfe+wTioqq1CFy+hPN/Sp1fIvhLO4TH2f/VZxYYFaM2VEnV9/Ptty64E8zdt4QJPH9pCfr4+2HshT25ZBKiqr0I5DTl3ZPUoFpRUa8PxCdWndwn107vnremlc3zhFNPeXVHk6tGWwv/YfL1KvuFD3h7gkLdiapVcW7dKr4/urXUSwbn4jUZv356lz6+Za/LvhWrvnmG7951qPumr6YN6Vna9gf1+1bRmsi55eoKKyCv35pj7atD9Pvg6HfjGkvUbNWKHYsEAlnuH9Kygpl8sY91G9hduzFRsWqN5twlRSXqHpX+/UZZ0jVVBarmFdWys82E+H80sUFRKgD7/bV+005KzbB2jF7iO6qke0Lu8SqXvfT1Ln1s019Zpe7jbFZRXuMH3LJfH688/7VtsGgX4+6hLleYT3mc+26r2T17ZlTB+nF+bvUKfI5jqUV6xtB5164xcD5evjkDFGry1J1csLd6mZj0PfPTlSLZv7q6i0Qs7iMkWHVj9Ffcp9/07Sgm1ZWvrocP3uo2R9n5mrIZ1aKa+oTFf1iNKjJ+9wlCp/v7YddKpLVAuVVrgUGuinCpeRQ5KPzw+/d87iMoUG+qm03KUbXl+tbQedZ9ymp2+bvKIy7TlSoL7xYWru30y+Pg7336PDIf3up900oH1LJe/L1dKdh/X/BrfXuD6x7t+3qu/1pqmjFBbk5/67SNqbo6MnSrXzUL5mLPrhVPbQrpF6+mc91aV1C/n4OFR+8prBqr/DhaXl2pdTpO4xISosLde4V1d5nF7uGNlcB44XacYtF2vzgVy9sbzy1Pvfbr1YGzKO65IOLXXdxW08+vva4t3668Jdahnsp/d+laA+bcPO+v7UFWEEaOQ+Sz6gz5MPasatFyv0DKeiGsqJknIFNPORn6/33VxnjNHXW7PUp03YBR9BO5xfrPAgf/fRrPSjBbryL8vc88+14zrsLNbm/Xm6qkeUx47wQG6RWjX3r3U4rauS8grlFpbpzRV79Ish7dW+VfNave71Zamasy5T/73vJzVev1aTvMIyPf6/TbpxQOVRh3Mxxqi0wlWnMZuMMSoqq1CwfzNVuIwKSsvr9Xd+xsJd+tvi3Ypo7q/vn/7peS0jK69YxwtLa/0P2YKtWapwGY3rG3vWdsYYHcwrVpsarvGri1Nhp8Jl5Ovj0OH8Yo15ZaWuuzjOI5TW5NRrGgJhBADOg8tl9HHSPvVv1/KCrwODdygpr9BXmw/psi6RZz1C09S4XMYjJFuBMAIAACx1Iftv7zsuCwAAbIUwAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACwFGEEAABYijACAAAs1WBhZObMmerQoYMCAwOVkJCg9evXN9SqAABAI9YgYeTDDz/UpEmTNHXqVH3//ffq16+fRo8ercOHDzfE6gAAQCPWIGHk5Zdf1oQJE3TXXXepZ8+e+sc//qHg4GC9/fbbDbE6AADQiDWr7wWWlpYqKSlJU6ZMcU/z8fHRyJEjlZiYWK19SUmJSkpK3M/z8vIkVX77HwAAaBxO7beNMXV+bb2HkaNHj6qiokLR0dEe06Ojo7Vz585q7adNm6bnnnuu2vT4+Pj6Lg0AADSw/Px8hYWF1ek19R5G6mrKlCmaNGmS+7nL5VJOTo5atWolh8NRr+tyOp2Kj4/Xvn37FBoaWq/L9gZNvX9S0+8j/Wv8mnof6V/j11B9NMYoPz9fcXFxdX5tvYeRyMhI+fr6Kjs722N6dna2YmJiqrUPCAhQQECAx7Tw8PD6LstDaGhok/0lk5p+/6Sm30f61/g19T7Sv8avIfpY1yMip9T7Baz+/v4aOHCgFi9e7J7mcrm0ePFiDRkypL5XBwAAGrkGOU0zadIk3XHHHbrkkks0aNAgvfLKKyooKNBdd93VEKsDAACNWIOEkVtuuUVHjhzRM888o6ysLF188cVasGBBtYtaf2wBAQGaOnVqtdNCTUVT75/U9PtI/xq/pt5H+tf4eWMfHeZ87sEBAACoJ3w3DQAAsBRhBAAAWIowAgAALEUYAQAAlrJNGJk5c6Y6dOigwMBAJSQkaP369VaXpGnTpunSSy9VSEiIoqKidP311yslJcWjzfDhw+VwODwe9913n0ebzMxMjRs3TsHBwYqKitJjjz2m8vJyjzbLli3TgAEDFBAQoC5dumj27NnV6mmI9+jZZ5+tVn+PHj3c84uLizVx4kS1atVKLVq00E033VRtwDxv7l+HDh2q9c/hcGjixImSGuf2W7Fiha655hrFxcXJ4XBo3rx5HvONMXrmmWcUGxuroKAgjRw5Urt37/Zok5OTo9tvv12hoaEKDw/X3XffrRMnTni02bx5s4YOHarAwEDFx8frxRdfrFbLxx9/rB49eigwMFB9+vTR/Pnz61xLXfpXVlamyZMnq0+fPmrevLni4uL0y1/+UgcPHvRYRk3bffr06V7fP0m68847q9U+ZswYjzbevP1q08ea/iYdDodeeukldxtv3oa12Td402dnbWo5J2MDc+fONf7+/ubtt98227ZtMxMmTDDh4eEmOzvb0rpGjx5t3nnnHbN161aTnJxsrr76atOuXTtz4sQJd5srrrjCTJgwwRw6dMj9yMvLc88vLy83vXv3NiNHjjQbN2408+fPN5GRkWbKlCnuNnv27DHBwcFm0qRJZvv27ea1114zvr6+ZsGCBe42DfUeTZ061fTq1cuj/iNHjrjn33fffSY+Pt4sXrzYbNiwwQwePNj85Cc/aTT9O3z4sEffFi5caCSZpUuXGmMa5/abP3++efLJJ80nn3xiJJlPP/3UY/706dNNWFiYmTdvntm0aZO59tprTceOHU1RUZG7zZgxY0y/fv3M2rVrzcqVK02XLl3M+PHj3fPz8vJMdHS0uf32283WrVvNBx98YIKCgswbb7zhbrN69Wrj6+trXnzxRbN9+3bz1FNPGT8/P7Nly5Y61VKX/uXm5pqRI0eaDz/80OzcudMkJiaaQYMGmYEDB3oso3379uYPf/iDx3at+nfrrf0zxpg77rjDjBkzxqP2nJwcjzbevP1q08eqfTt06JB5++23jcPhMGlpae423rwNa7Nv8KbPznPVUhu2CCODBg0yEydOdD+vqKgwcXFxZtq0aRZWVd3hw4eNJLN8+XL3tCuuuMI8/PDDZ3zN/PnzjY+Pj8nKynJPmzVrlgkNDTUlJSXGGGMef/xx06tXL4/X3XLLLWb06NHu5w31Hk2dOtX069evxnm5ubnGz8/PfPzxx+5pO3bsMJJMYmJio+jf6R5++GHTuXNn43K5jDGNf/ud/kHvcrlMTEyMeemll9zTcnNzTUBAgPnggw+MMcZs377dSDLfffedu83XX39tHA6HOXDggDHGmNdff920bNnS3UdjjJk8ebLp3r27+/nNN99sxo0b51FPQkKCuffee2tdS137V5P169cbSWbv3r3uae3btzczZsw442u8uX933HGHue666874msa0/c7Ux9Ndd9115qqrrvKY1li2oTHV9w3e9NlZm1pqo8mfpiktLVVSUpJGjhzpnubj46ORI0cqMTHRwsqqy8vLkyRFRER4TP/Pf/6jyMhI9e7dW1OmTFFhYaF7XmJiovr06eMxoNzo0aPldDq1bds2d5uq/T/V5lT/G/o92r17t+Li4tSpUyfdfvvtyszMlCQlJSWprKzMY709evRQu3bt3OttDP07pbS0VO+//75+9atfeXzJY2PfflWlp6crKyvLY11hYWFKSEjw2Gbh4eG65JJL3G1GjhwpHx8frVu3zt1m2LBh8vf39+hTSkqKjh8/Xqt+16aW+pCXlyeHw1HtO7OmT5+uVq1aqX///nrppZc8Dn97e/+WLVumqKgode/eXffff7+OHTvmUXtT2n7Z2dn66quvdPfdd1eb11i24en7Bm/67KxNLbVh+bf2NrSjR4+qoqKi2uiv0dHR2rlzp0VVVedyufTII4/osssuU+/evd3Tb7vtNrVv315xcXHavHmzJk+erJSUFH3yySeSpKysrBr7dmre2do4nU4VFRXp+PHjDfYeJSQkaPbs2erevbsOHTqk5557TkOHDtXWrVuVlZUlf3//ah/y0dHR56zdW/pX1bx585Sbm6s777zTPa2xb7/TnaqppnVVrTcqKspjfrNmzRQREeHRpmPHjtWWcWpey5Ytz9jvqss4Vy0Xqri4WJMnT9b48eM9vlDsoYce0oABAxQREaE1a9ZoypQpOnTokF5++WWv79+YMWN04403qmPHjkpLS9MTTzyhsWPHKjExUb6+vk1q+0nSu+++q5CQEN14440e0xvLNqxp3+BNn521qaU2mnwYaSwmTpyorVu3atWqVR7T77nnHvfPffr0UWxsrEaMGKG0tDR17tz5xy6zzsaOHev+uW/fvkpISFD79u310UcfKSgoyMLK6t9bb72lsWPHenx9dmPffnZWVlamm2++WcYYzZo1y2PepEmT3D/37dtX/v7+uvfeezVt2jSvGmK7Jrfeeqv75z59+qhv377q3Lmzli1bphEjRlhYWcN4++23dfvttyswMNBjemPZhmfaNzQ1Tf40TWRkpHx9fatd2Zudna2YmBiLqvL0wAMP6Msvv9TSpUvVtm3bs7ZNSEiQJKWmpkqSYmJiauzbqXlnaxMaGqqgoKAf9T0KDw9Xt27dlJqaqpiYGJWWlio3N/eM620s/du7d68WLVqkX//612dt19i336nlnW1dMTExOnz4sMf88vJy5eTk1Mt2rTr/XLWcr1NBZO/evVq4cOE5v2Y9ISFB5eXlysjIOGvtVeu2sn9VderUSZGRkR6/k419+52ycuVKpaSknPPvUvLObXimfYM3fXbWppbaaPJhxN/fXwMHDtTixYvd01wulxYvXqwhQ4ZYWFnlLV8PPPCAPv30Uy1ZsqTaIcGaJCcnS5JiY2MlSUOGDNGWLVs8PjxOfXj27NnT3aZq/0+1OdX/H/M9OnHihNLS0hQbG6uBAwfKz8/PY70pKSnKzMx0r7ex9O+dd95RVFSUxo0bd9Z2jX37dezYUTExMR7rcjqdWrduncc2y83NVVJSkrvNkiVL5HK53GFsyJAhWrFihcrKyjz61L17d7Vs2bJW/a5NLefjVBDZvXu3Fi1apFatWp3zNcnJyfLx8XGf3vDm/p1u//79OnbsmMfvZGPeflW99dZbGjhwoPr163fOtt60Dc+1b/Cmz87a1FIrtb7UtRGbO3euCQgIMLNnzzbbt28399xzjwkPD/e4ytgK999/vwkLCzPLli3zuL2ssLDQGGNMamqq+cMf/mA2bNhg0tPTzWeffWY6depkhg0b5l7Gqdu3Ro0aZZKTk82CBQtM69ata7x967HHHjM7duwwM2fOrPH2rYZ4j373u9+ZZcuWmfT0dLN69WozcuRIExkZaQ4fPmyMqbwlrF27dmbJkiVmw4YNZsiQIWbIkCGNpn/GVF5d3q5dOzN58mSP6Y11++Xn55uNGzeajRs3Gknm5ZdfNhs3bnTfTTJ9+nQTHh5uPvvsM7N582Zz3XXX1Xhrb//+/c26devMqlWrTNeuXT1uDc3NzTXR0dHmF7/4hdm6dauZO3euCQ4OrnbbZLNmzcxf/vIXs2PHDjN16tQab5s8Vy116V9paam59tprTdu2bU1ycrLH3+WpOxDWrFljZsyYYZKTk01aWpp5//33TevWrc0vf/lLr+9ffn6+efTRR01iYqJJT083ixYtMgMGDDBdu3Y1xcXFjWL7nauPp+Tl5Zng4GAza9asaq/39m14rn2DMd712XmuWmrDFmHEGGNee+01065dO+Pv728GDRpk1q5da3VJRlKNj3feeccYY0xmZqYZNmyYiYiIMAEBAaZLly7mscce8xinwhhjMjIyzNixY01QUJCJjIw0v/vd70xZWZlHm6VLl5qLL77Y+Pv7m06dOrnXUVVDvEe33HKLiY2NNf7+/qZNmzbmlltuMampqe75RUVF5je/+Y1p2bKlCQ4ONjfccIM5dOhQo+mfMcZ88803RpJJSUnxmN5Yt9/SpUtr/L284447jDGVtys+/fTTJjo62gQEBJgRI0ZU6/uxY8fM+PHjTYsWLUxoaKi56667TH5+vkebTZs2mcsvv9wEBASYNm3amOnTp1er5aOPPjLdunUz/v7+plevXuarr77ymF+bWurSv/T09DP+XZ4aOyYpKckkJCSYsLAwExgYaC666CLzwgsveOzMvbV/hYWFZtSoUaZ169bGz8/PtG/f3kyYMKFaaPXm7XeuPp7yxhtvmKCgIJObm1vt9d6+Dc+1bzDGuz47a1PLuThOdhwAAMASTf6aEQAA4N0IIwAAwFKEEQAAYCnCCAAAsBRhBAAAWIowAgAALEUYAQAAliKMAAAASxFGAACApQgjAADAUoQRAABgKcIIAACw1P8HNuzEt6wDisMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a8d13f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.124398946762085\n",
      "val 2.1663334369659424\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def split_loss(split):\n",
    "    x,y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val':   (Xdev, Ydev),\n",
    "        'test':  (Xte, Yte),\n",
    "    }[split]\n",
    "    emb = C[x]\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    h = torch.tanh(embcat @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "    \n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c053d3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "osz.\n",
      "harihalara.\n",
      "avean.\n",
      "dulla.\n",
      "wadeanstayton.\n",
      "shel.\n",
      "dur.\n",
      "wavia.\n",
      "sardon.\n",
      "kashloett.\n",
      "mackylberklyn.\n",
      "jagm.\n",
      "ajaov.\n",
      "kashamsyra.\n",
      "abbeoten.\n",
      "hadlisen.\n",
      "colla.\n",
      "samena.\n",
      "kai.\n",
      "angelnessirie.\n"
     ]
    }
   ],
   "source": [
    "# sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True: \n",
    "        # forward pass\n",
    "        emb = C[torch.tensor([context])]\n",
    "        h = torch.tanh(emb.view(1,-1) @ W1 + b1)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item();\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        \n",
    "        if ix == 0:\n",
    "            break;\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2543034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorchify the above code to modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1283d1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear: \n",
    "\n",
    "    def __init__(self, fan_in, fan_out, bias=True):\n",
    "        self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
    "        self.bias = torch.zeros(fan_out) if bias else None\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.out = x @ self.weight\n",
    "        if self.bias is not None:\n",
    "            self.out += self.bias\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "    \n",
    "\n",
    "class BatchNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        self.training = True\n",
    "        # parameters (trained with backprop)\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta  = torch.zeros(dim)\n",
    "        # buffers (trained with a running momemtum update)\n",
    "        self.running_mean = torch.zeros(dim)\n",
    "        self.running_var  = torch.ones(dim)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        if self.training:\n",
    "            xmean = x.mean(0, keepdim=True)\n",
    "            xvar   = x.var(0, keepdim=True)\n",
    "        else:\n",
    "            xmeam = self.running_mean\n",
    "            xvar  = self.running_var\n",
    "        xhat = (x-xmean) / torch.sqrt(xvar + self.eps)\n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        #update the buffers\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "                self.running_var  = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "        return self.out \n",
    "    \n",
    "    def parameters(self):\n",
    "            return [self.gamma, self.beta]\n",
    "        \n",
    "        \n",
    "class Tanh:\n",
    "    def __call__(self, x):\n",
    "        self.out = torch.tanh(x)\n",
    "        return self.out\n",
    "    def parameters(self):\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "455039f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47497\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "n_embd = 10\n",
    "n_hidden = 100\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "layers = [\n",
    "    Linear(n_embd * block_size, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, n_hidden), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(           n_hidden, vocab_size),\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    layers[-1].weight *= 0.1   # last layer: make less confident\n",
    "    for layer in layers[:-1]:  # all other layers : apply gain\n",
    "        if isinstance(layer, Linear):\n",
    "            layer.weight *= 5/3\n",
    "            \n",
    "parameters = [C] + [p for layer in layers for p in layer.parameters()]\n",
    "print(sum(p.nelement() for p in parameters))  # total number of parameters\n",
    "for p in parameters:\n",
    "    p.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "73724b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.2869\n",
      "  10000/ 200000: 2.3536\n",
      "  20000/ 200000: 2.0481\n",
      "  30000/ 200000: 1.9798\n",
      "  40000/ 200000: 2.1022\n",
      "  50000/ 200000: 2.3221\n",
      "  60000/ 200000: 1.8259\n",
      "  70000/ 200000: 2.2275\n",
      "  80000/ 200000: 2.2852\n",
      "  90000/ 200000: 1.8405\n",
      " 100000/ 200000: 2.4169\n",
      " 110000/ 200000: 2.1714\n",
      " 120000/ 200000: 2.0479\n",
      " 130000/ 200000: 2.0398\n",
      " 140000/ 200000: 1.7486\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [116], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[1;32m     22\u001b[0m     p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# update\u001b[39;00m\n\u001b[1;32m     26\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m100000\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.01\u001b[39m\n",
      "File \u001b[0;32m~/Repositories/pytorch/venv/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Repositories/pytorch/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "\n",
    "for i in range(max_steps):\n",
    "    # mini-batch\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix]  # batch X,Y\n",
    "    \n",
    "    # forward pass\n",
    "    emb = C[Xb]  # (32, 3, 2)\n",
    "    x = emb.view(emb.shape[0], -1)\n",
    "    for layer in layers:\n",
    "        x = layer(x)\n",
    "    loss = F.cross_entropy(x, Yb)\n",
    "\n",
    "    # backward \n",
    "    for layer in layers:\n",
    "        layer.out.retain_grad()\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward()\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "        \n",
    "    # track stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f\"{i:7d}/{max_steps:7d}: {loss.item():.4f}\")\n",
    "    lossi.append(loss.log10().item())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef30f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
