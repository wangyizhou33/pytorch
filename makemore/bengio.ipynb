{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba030d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/yizhouw/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/yizhouw/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15667"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download(\"brown\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "len(brown.paras())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "273e629d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12681"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = 12000\n",
    "UNK_symbol = '<UNK>'\n",
    "vocab = set([UNK_symbol])\n",
    "\n",
    "# create brown corpus again with all words\n",
    "# no preprocessing, only lowercase\n",
    "brown_corpus_train = []\n",
    "for idx, paragraph in enumerate(brown.paras()):\n",
    "    if idx == num_train:\n",
    "        break\n",
    "    words = []\n",
    "    for sentence in paragraph:\n",
    "        for word in sentence:\n",
    "            words.append(word.lower())\n",
    "    brown_corpus_train.append(words)\n",
    "    \n",
    "# create term frequency of the words\n",
    "words_term_frequency_train = {}\n",
    "for doc in brown_corpus_train:\n",
    "    for word in doc:\n",
    "        words_term_frequency_train[word] = words_term_frequency_train.get(word,0) + 1\n",
    "\n",
    "# create vocabulary\n",
    "for doc in brown_corpus_train:\n",
    "    for word in doc:\n",
    "        if words_term_frequency_train.get(word, 0) >= 5:\n",
    "            vocab.add(word)\n",
    "\n",
    "len(vocab)  # 12681\n",
    "            # vocab has no dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5343d410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(872823, 2)\n",
      "(872823, 1)\n",
      "(174016, 2)\n",
      "(174016, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "x_train = []\n",
    "y_train = []\n",
    "x_dev = []\n",
    "y_dev = []\n",
    "\n",
    "\n",
    "# create word to id mappings\n",
    "word_to_id_mappings = {}\n",
    "for idx, word in enumerate(vocab):\n",
    "    word_to_id_mappings[word] = idx\n",
    "\n",
    "    \n",
    "# function to get id for a given word\n",
    "# return <UNK> id if not found\n",
    "def get_id_of_word(word):\n",
    "    unknown_word_id = word_to_id_mappings['<UNK>']\n",
    "    return word_to_id_mappings.get(word, unknown_word_id)\n",
    "                              \n",
    "   \n",
    "# create training and dev set\n",
    "for idx, paragraph in enumerate(brown.paras()):   \n",
    "    for sentence in paragraph:\n",
    "        for i, word in enumerate(sentence):\n",
    "            if i + 2 >= len(sentence):\n",
    "                # sentence boundary reached\n",
    "                # ignoring sentence less than 3 words\n",
    "                break\n",
    "            x_extract = [get_id_of_word(word.lower), get_id_of_word(sentence[i+1].lower())]\n",
    "            y_extract = [get_id_of_word(sentence[i+2].lower())]\n",
    "                                   \n",
    "            if idx < num_train:\n",
    "                x_train.append(x_extract)\n",
    "                y_train.append(y_extract)\n",
    "            else: \n",
    "                x_dev.append(x_extract)\n",
    "                y_dev.append(y_extract)\n",
    "                \n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_dev   = np.array(x_dev)\n",
    "y_dev   = np.array(y_dev)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_dev.shape)\n",
    "print(y_dev.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c560ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import torch\n",
    "import multiprocessing\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# Trigram Neural Network Model\n",
    "class TrigramNNmodel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size, h):\n",
    "        super(TrigramNNmodel, self).__init__()\n",
    "        self.context_size = context_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, h)\n",
    "        self.linear2 = nn.Linear(h, vocab_size, bias = False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # compute x': concatenation of x1 and x2 embeddings\n",
    "        embeds = self.embeddings(inputs).view((-1,self.context_size * self.embedding_dim))\n",
    "        # compute h: tanh(W_1.x' + b)\n",
    "        out = torch.tanh(self.linear1(embeds))\n",
    "        # compute W_2.h\n",
    "        out = self.linear2(out)\n",
    "        # compute y: log_softmax(W_2.h)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        # return log probabilities\n",
    "        # BATCH_SIZE x len(vocab)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c08339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Creating training and dev dataloaders with 256 batch size ---\n"
     ]
    }
   ],
   "source": [
    "# create parameters\n",
    "gpu = 0 \n",
    "# word vectors size\n",
    "EMBEDDING_DIM = 200\n",
    "CONTEXT_SIZE = 2\n",
    "BATCH_SIZE = 256\n",
    "# hidden units\n",
    "H = 100\n",
    "torch.manual_seed(13013)\n",
    "\n",
    "# check if gpu is available\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "available_workers = multiprocessing.cpu_count()\n",
    "\n",
    "print(\"--- Creating training and dev dataloaders with {} batch size ---\".format(BATCH_SIZE))\n",
    "train_set = np.concatenate((x_train, y_train), axis=1)\n",
    "dev_set = np.concatenate((x_dev, y_dev), axis=1)\n",
    "train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, num_workers = available_workers)\n",
    "dev_loader = DataLoader(dev_set, batch_size = BATCH_SIZE, num_workers = available_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3370fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get accuracy from log probabilities\n",
    "def get_accuracy_from_log_probs(log_probs, labels):\n",
    "    probs = torch.exp(log_probs)\n",
    "    predicted_label = torch.argmax(probs, dim=1)\n",
    "    acc = (predicted_label == labels).float().mean()\n",
    "    return acc\n",
    "\n",
    "# helper function to evaluate model on dev data\n",
    "def evaluate(model, criterion, dataloader, gpu):\n",
    "    model.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        dev_st = time.time()\n",
    "        for it, data_tensor in enumerate(dataloader):\n",
    "            context_tensor = data_tensor[:,0:2]\n",
    "            target_tensor = data_tensor[:,2]\n",
    "            context_tensor, target_tensor = context_tensor.cuda(gpu), target_tensor.cuda(gpu)\n",
    "            log_probs = model(context_tensor)\n",
    "            mean_loss += criterion(log_probs, target_tensor).item()\n",
    "            mean_acc += get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "            count += 1\n",
    "            if it % 500 == 0: \n",
    "                print(\"Dev Iteration {} complete. Mean Loss: {}; Mean Acc:{}; Time taken (s): {}\".format(it, mean_loss / count, mean_acc / count, (time.time()-dev_st)))\n",
    "                dev_st = time.time()\n",
    "\n",
    "    return mean_acc / count, mean_loss / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "a345db99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training model Epoch: 1 ---\n",
      "Training Iteration 0 of epoch 0 complete. Loss: 9.512959480285645; Acc:0.0; Time taken (s): 0.4376358985900879\n",
      "Training Iteration 500 of epoch 0 complete. Loss: 6.362466335296631; Acc:0.12109375; Time taken (s): 0.7990531921386719\n",
      "Training Iteration 1000 of epoch 0 complete. Loss: 6.119363307952881; Acc:0.140625; Time taken (s): 0.7724261283874512\n",
      "Training Iteration 1500 of epoch 0 complete. Loss: 6.059145450592041; Acc:0.11328125; Time taken (s): 0.7673954963684082\n",
      "Training Iteration 2000 of epoch 0 complete. Loss: 5.998517036437988; Acc:0.11328125; Time taken (s): 0.7977237701416016\n",
      "Training Iteration 2500 of epoch 0 complete. Loss: 6.223663330078125; Acc:0.12109375; Time taken (s): 0.7737562656402588\n",
      "Training Iteration 3000 of epoch 0 complete. Loss: 5.791821002960205; Acc:0.14453125; Time taken (s): 0.7659680843353271\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.0850114822387695; Mean Acc:0.17578125; Time taken (s): 0.4415891170501709\n",
      "Dev Iteration 500 complete. Mean Loss: 5.1962247399274935; Mean Acc:0.1596728414297104; Time taken (s): 0.4181239604949951\n",
      "Epoch 0 complete! Development Accuracy: 0.1585478037595749; Development Loss: 5.207465780482573\n",
      "Best development accuracy improved from 0 to 0.1585478037595749, saving model...\n",
      "\n",
      "--- Training model Epoch: 2 ---\n",
      "Training Iteration 0 of epoch 1 complete. Loss: 6.440006256103516; Acc:0.125; Time taken (s): 0.440218448638916\n",
      "Training Iteration 500 of epoch 1 complete. Loss: 5.81879186630249; Acc:0.16015625; Time taken (s): 0.809758186340332\n",
      "Training Iteration 1000 of epoch 1 complete. Loss: 5.589663982391357; Acc:0.1953125; Time taken (s): 0.7718520164489746\n",
      "Training Iteration 1500 of epoch 1 complete. Loss: 5.752180576324463; Acc:0.125; Time taken (s): 0.7745406627655029\n",
      "Training Iteration 2000 of epoch 1 complete. Loss: 5.643042087554932; Acc:0.14453125; Time taken (s): 0.770477294921875\n",
      "Training Iteration 2500 of epoch 1 complete. Loss: 5.688634395599365; Acc:0.16015625; Time taken (s): 0.7693116664886475\n",
      "Training Iteration 3000 of epoch 1 complete. Loss: 5.361946105957031; Acc:0.16796875; Time taken (s): 0.768333911895752\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.121412754058838; Mean Acc:0.19140625; Time taken (s): 0.4413740634918213\n",
      "Dev Iteration 500 complete. Mean Loss: 5.181053959205003; Mean Acc:0.16142714023590088; Time taken (s): 0.41841864585876465\n",
      "Epoch 1 complete! Development Accuracy: 0.15954351425170898; Development Loss: 5.193425220601699\n",
      "Best development accuracy improved from 0.1585478037595749 to 0.15954351425170898, saving model...\n",
      "\n",
      "--- Training model Epoch: 3 ---\n",
      "Training Iteration 0 of epoch 2 complete. Loss: 6.096646785736084; Acc:0.12890625; Time taken (s): 0.4334421157836914\n",
      "Training Iteration 500 of epoch 2 complete. Loss: 5.5531229972839355; Acc:0.16015625; Time taken (s): 0.7948362827301025\n",
      "Training Iteration 1000 of epoch 2 complete. Loss: 5.371721267700195; Acc:0.203125; Time taken (s): 0.7843413352966309\n",
      "Training Iteration 1500 of epoch 2 complete. Loss: 5.535014629364014; Acc:0.13671875; Time taken (s): 0.773949146270752\n",
      "Training Iteration 2000 of epoch 2 complete. Loss: 5.455606937408447; Acc:0.13671875; Time taken (s): 0.7683672904968262\n",
      "Training Iteration 2500 of epoch 2 complete. Loss: 5.475379943847656; Acc:0.15234375; Time taken (s): 0.786707878112793\n",
      "Training Iteration 3000 of epoch 2 complete. Loss: 5.140048027038574; Acc:0.16796875; Time taken (s): 0.7763571739196777\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.158316612243652; Mean Acc:0.1875; Time taken (s): 0.4434530735015869\n",
      "Dev Iteration 500 complete. Mean Loss: 5.205393022167945; Mean Acc:0.16382859647274017; Time taken (s): 0.41484522819519043\n",
      "Epoch 2 complete! Development Accuracy: 0.1626206338405609; Development Loss: 5.21776344425538\n",
      "Best development accuracy improved from 0.15954351425170898 to 0.1626206338405609, saving model...\n",
      "\n",
      "--- Training model Epoch: 4 ---\n",
      "Training Iteration 0 of epoch 3 complete. Loss: 5.8756489753723145; Acc:0.14453125; Time taken (s): 0.4314005374908447\n",
      "Training Iteration 500 of epoch 3 complete. Loss: 5.378365516662598; Acc:0.18359375; Time taken (s): 0.8000867366790771\n",
      "Training Iteration 1000 of epoch 3 complete. Loss: 5.202795028686523; Acc:0.22265625; Time taken (s): 0.7679200172424316\n",
      "Training Iteration 1500 of epoch 3 complete. Loss: 5.4210686683654785; Acc:0.14453125; Time taken (s): 0.7887704372406006\n",
      "Training Iteration 2000 of epoch 3 complete. Loss: 5.339476585388184; Acc:0.140625; Time taken (s): 0.8081834316253662\n",
      "Training Iteration 2500 of epoch 3 complete. Loss: 5.338962554931641; Acc:0.16015625; Time taken (s): 0.776029109954834\n",
      "Training Iteration 3000 of epoch 3 complete. Loss: 4.960082054138184; Acc:0.18359375; Time taken (s): 0.7777307033538818\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.186918258666992; Mean Acc:0.17578125; Time taken (s): 0.4270601272583008\n",
      "Dev Iteration 500 complete. Mean Loss: 5.248208510423611; Mean Acc:0.16071762144565582; Time taken (s): 0.42272019386291504\n",
      "Epoch 3 complete! Development Accuracy: 0.15929840505123138; Development Loss: 5.261610300400678\n",
      "\n",
      "--- Training model Epoch: 5 ---\n",
      "Training Iteration 0 of epoch 4 complete. Loss: 5.737853050231934; Acc:0.140625; Time taken (s): 0.44275665283203125\n",
      "Training Iteration 500 of epoch 4 complete. Loss: 5.270014762878418; Acc:0.16796875; Time taken (s): 0.7866239547729492\n",
      "Training Iteration 1000 of epoch 4 complete. Loss: 5.068617343902588; Acc:0.19921875; Time taken (s): 0.7698161602020264\n",
      "Training Iteration 1500 of epoch 4 complete. Loss: 5.349738597869873; Acc:0.14453125; Time taken (s): 0.7692282199859619\n",
      "Training Iteration 2000 of epoch 4 complete. Loss: 5.24205207824707; Acc:0.13671875; Time taken (s): 0.770991325378418\n",
      "Training Iteration 2500 of epoch 4 complete. Loss: 5.233527183532715; Acc:0.17578125; Time taken (s): 0.771028995513916\n",
      "Training Iteration 3000 of epoch 4 complete. Loss: 4.79541540145874; Acc:0.1953125; Time taken (s): 0.77266526222229\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.19749116897583; Mean Acc:0.19140625; Time taken (s): 0.43484067916870117\n",
      "Dev Iteration 500 complete. Mean Loss: 5.280320239876083; Mean Acc:0.1595870703458786; Time taken (s): 0.4100160598754883\n",
      "Epoch 4 complete! Development Accuracy: 0.15854397416114807; Development Loss: 5.294963943958282\n",
      "\n",
      "--- Training model Epoch: 6 ---\n",
      "Training Iteration 0 of epoch 5 complete. Loss: 5.598718643188477; Acc:0.15234375; Time taken (s): 0.4366931915283203\n",
      "Training Iteration 500 of epoch 5 complete. Loss: 5.187792778015137; Acc:0.1640625; Time taken (s): 0.8117132186889648\n",
      "Training Iteration 1000 of epoch 5 complete. Loss: 5.020382881164551; Acc:0.1953125; Time taken (s): 0.8003630638122559\n",
      "Training Iteration 1500 of epoch 5 complete. Loss: 5.290127754211426; Acc:0.14453125; Time taken (s): 0.771979570388794\n",
      "Training Iteration 2000 of epoch 5 complete. Loss: 5.16017484664917; Acc:0.14453125; Time taken (s): 0.7890515327453613\n",
      "Training Iteration 2500 of epoch 5 complete. Loss: 5.116795063018799; Acc:0.1875; Time taken (s): 0.7667860984802246\n",
      "Training Iteration 3000 of epoch 5 complete. Loss: 4.7576446533203125; Acc:0.2109375; Time taken (s): 0.7779710292816162\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.213930130004883; Mean Acc:0.19140625; Time taken (s): 0.432403564453125\n",
      "Dev Iteration 500 complete. Mean Loss: 5.313776587297816; Mean Acc:0.1617078334093094; Time taken (s): 0.4265425205230713\n",
      "Epoch 5 complete! Development Accuracy: 0.16072113811969757; Development Loss: 5.327966948116527\n",
      "\n",
      "--- Training model Epoch: 7 ---\n",
      "Training Iteration 0 of epoch 6 complete. Loss: 5.510840892791748; Acc:0.1640625; Time taken (s): 0.44474244117736816\n",
      "Training Iteration 500 of epoch 6 complete. Loss: 5.114985942840576; Acc:0.17578125; Time taken (s): 0.792933464050293\n",
      "Training Iteration 1000 of epoch 6 complete. Loss: 5.018610000610352; Acc:0.19140625; Time taken (s): 0.7865073680877686\n",
      "Training Iteration 1500 of epoch 6 complete. Loss: 5.245650768280029; Acc:0.14453125; Time taken (s): 0.771773099899292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 2000 of epoch 6 complete. Loss: 5.132070541381836; Acc:0.1484375; Time taken (s): 0.7726919651031494\n",
      "Training Iteration 2500 of epoch 6 complete. Loss: 5.074798107147217; Acc:0.1875; Time taken (s): 0.7776980400085449\n",
      "Training Iteration 3000 of epoch 6 complete. Loss: 4.740074634552002; Acc:0.22265625; Time taken (s): 0.7776341438293457\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.252227783203125; Mean Acc:0.1875; Time taken (s): 0.4313945770263672\n",
      "Dev Iteration 500 complete. Mean Loss: 5.349879317178935; Mean Acc:0.161208838224411; Time taken (s): 0.43974781036376953\n",
      "Epoch 6 complete! Development Accuracy: 0.16123047471046448; Development Loss: 5.363751313966863\n",
      "\n",
      "--- Training model Epoch: 8 ---\n",
      "Training Iteration 0 of epoch 7 complete. Loss: 5.413658618927002; Acc:0.15625; Time taken (s): 0.44055867195129395\n",
      "Training Iteration 500 of epoch 7 complete. Loss: 5.082083225250244; Acc:0.18359375; Time taken (s): 0.7970316410064697\n",
      "Training Iteration 1000 of epoch 7 complete. Loss: 4.995424747467041; Acc:0.203125; Time taken (s): 0.7768492698669434\n",
      "Training Iteration 1500 of epoch 7 complete. Loss: 5.19575834274292; Acc:0.15625; Time taken (s): 0.7710049152374268\n",
      "Training Iteration 2000 of epoch 7 complete. Loss: 5.114561080932617; Acc:0.15234375; Time taken (s): 0.7712750434875488\n",
      "Training Iteration 2500 of epoch 7 complete. Loss: 5.051124572753906; Acc:0.19921875; Time taken (s): 0.7750370502471924\n",
      "Training Iteration 3000 of epoch 7 complete. Loss: 4.735202789306641; Acc:0.1953125; Time taken (s): 0.7888748645782471\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.284581184387207; Mean Acc:0.1875; Time taken (s): 0.4399886131286621\n",
      "Dev Iteration 500 complete. Mean Loss: 5.37921421446962; Mean Acc:0.16132578253746033; Time taken (s): 0.41900181770324707\n",
      "Epoch 7 complete! Development Accuracy: 0.16134344041347504; Development Loss: 5.392240707313313\n",
      "\n",
      "--- Training model Epoch: 9 ---\n",
      "Training Iteration 0 of epoch 8 complete. Loss: 5.3194427490234375; Acc:0.16015625; Time taken (s): 0.43285393714904785\n",
      "Training Iteration 500 of epoch 8 complete. Loss: 5.045388698577881; Acc:0.1875; Time taken (s): 0.8047702312469482\n",
      "Training Iteration 1000 of epoch 8 complete. Loss: 4.976797580718994; Acc:0.203125; Time taken (s): 0.779426097869873\n",
      "Training Iteration 1500 of epoch 8 complete. Loss: 5.165067195892334; Acc:0.15234375; Time taken (s): 0.7900617122650146\n",
      "Training Iteration 2000 of epoch 8 complete. Loss: 5.088719367980957; Acc:0.15625; Time taken (s): 0.7743475437164307\n",
      "Training Iteration 2500 of epoch 8 complete. Loss: 5.045433044433594; Acc:0.19140625; Time taken (s): 0.7706253528594971\n",
      "Training Iteration 3000 of epoch 8 complete. Loss: 4.715944766998291; Acc:0.2265625; Time taken (s): 0.778994083404541\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.318556308746338; Mean Acc:0.18359375; Time taken (s): 0.42981934547424316\n",
      "Dev Iteration 500 complete. Mean Loss: 5.415891888136874; Mean Acc:0.1610528975725174; Time taken (s): 0.4149439334869385\n",
      "Epoch 8 complete! Development Accuracy: 0.16081878542900085; Development Loss: 5.428721839540145\n",
      "\n",
      "--- Training model Epoch: 10 ---\n",
      "Training Iteration 0 of epoch 9 complete. Loss: 5.245691776275635; Acc:0.17578125; Time taken (s): 0.4283413887023926\n",
      "Training Iteration 500 of epoch 9 complete. Loss: 5.01057243347168; Acc:0.203125; Time taken (s): 0.8291223049163818\n",
      "Training Iteration 1000 of epoch 9 complete. Loss: 4.950498580932617; Acc:0.19921875; Time taken (s): 0.7781925201416016\n",
      "Training Iteration 1500 of epoch 9 complete. Loss: 5.164092540740967; Acc:0.16015625; Time taken (s): 0.7731478214263916\n",
      "Training Iteration 2000 of epoch 9 complete. Loss: 5.081826686859131; Acc:0.15234375; Time taken (s): 0.7721908092498779\n",
      "Training Iteration 2500 of epoch 9 complete. Loss: 4.9887614250183105; Acc:0.1953125; Time taken (s): 0.7670707702636719\n",
      "Training Iteration 3000 of epoch 9 complete. Loss: 4.713754177093506; Acc:0.21484375; Time taken (s): 0.7687597274780273\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.344647407531738; Mean Acc:0.1796875; Time taken (s): 0.43875980377197266\n",
      "Dev Iteration 500 complete. Mean Loss: 5.442049862143998; Mean Acc:0.1604369431734085; Time taken (s): 0.4363279342651367\n",
      "Epoch 9 complete! Development Accuracy: 0.15998008847236633; Development Loss: 5.454294123369105\n",
      "\n",
      "--- Training model Epoch: 11 ---\n",
      "Training Iteration 0 of epoch 10 complete. Loss: 5.228044509887695; Acc:0.17578125; Time taken (s): 0.4289708137512207\n",
      "Training Iteration 500 of epoch 10 complete. Loss: 4.966592311859131; Acc:0.19921875; Time taken (s): 0.8104665279388428\n",
      "Training Iteration 1000 of epoch 10 complete. Loss: 4.920793056488037; Acc:0.21484375; Time taken (s): 0.7728829383850098\n",
      "Training Iteration 1500 of epoch 10 complete. Loss: 5.170679092407227; Acc:0.15625; Time taken (s): 0.7816781997680664\n",
      "Training Iteration 2000 of epoch 10 complete. Loss: 5.047520637512207; Acc:0.16015625; Time taken (s): 0.7779390811920166\n",
      "Training Iteration 2500 of epoch 10 complete. Loss: 5.000730514526367; Acc:0.1953125; Time taken (s): 0.7857556343078613\n",
      "Training Iteration 3000 of epoch 10 complete. Loss: 4.704352378845215; Acc:0.19140625; Time taken (s): 0.7726871967315674\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.348916053771973; Mean Acc:0.17578125; Time taken (s): 0.4373037815093994\n",
      "Dev Iteration 500 complete. Mean Loss: 5.460779514617311; Mean Acc:0.15888535976409912; Time taken (s): 0.41905903816223145\n",
      "Epoch 10 complete! Development Accuracy: 0.15837164223194122; Development Loss: 5.47236574607737\n",
      "\n",
      "--- Training model Epoch: 12 ---\n",
      "Training Iteration 0 of epoch 11 complete. Loss: 5.188605785369873; Acc:0.16796875; Time taken (s): 0.43420839309692383\n",
      "Training Iteration 500 of epoch 11 complete. Loss: 4.971179008483887; Acc:0.19921875; Time taken (s): 0.7846171855926514\n",
      "Training Iteration 1000 of epoch 11 complete. Loss: 4.908289432525635; Acc:0.21484375; Time taken (s): 0.8027153015136719\n",
      "Training Iteration 1500 of epoch 11 complete. Loss: 5.146185398101807; Acc:0.14453125; Time taken (s): 0.7705478668212891\n",
      "Training Iteration 2000 of epoch 11 complete. Loss: 5.027726650238037; Acc:0.15234375; Time taken (s): 0.7687520980834961\n",
      "Training Iteration 2500 of epoch 11 complete. Loss: 4.9481520652771; Acc:0.1953125; Time taken (s): 0.7712523937225342\n",
      "Training Iteration 3000 of epoch 11 complete. Loss: 4.710184097290039; Acc:0.21875; Time taken (s): 0.7726452350616455\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.373419284820557; Mean Acc:0.17578125; Time taken (s): 0.426424503326416\n",
      "Dev Iteration 500 complete. Mean Loss: 5.485172021412802; Mean Acc:0.15849551558494568; Time taken (s): 0.42481017112731934\n",
      "Epoch 11 complete! Development Accuracy: 0.15808631479740143; Development Loss: 5.495760358782375\n",
      "\n",
      "--- Training model Epoch: 13 ---\n",
      "Training Iteration 0 of epoch 12 complete. Loss: 5.168015480041504; Acc:0.1640625; Time taken (s): 0.44419050216674805\n",
      "Training Iteration 500 of epoch 12 complete. Loss: 4.914538860321045; Acc:0.1875; Time taken (s): 0.8003911972045898\n",
      "Training Iteration 1000 of epoch 12 complete. Loss: 4.920185565948486; Acc:0.2421875; Time taken (s): 0.7743749618530273\n",
      "Training Iteration 1500 of epoch 12 complete. Loss: 5.13255500793457; Acc:0.1484375; Time taken (s): 0.7804908752441406\n",
      "Training Iteration 2000 of epoch 12 complete. Loss: 5.04554557800293; Acc:0.15625; Time taken (s): 0.7841227054595947\n",
      "Training Iteration 2500 of epoch 12 complete. Loss: 4.924422740936279; Acc:0.16796875; Time taken (s): 0.7764260768890381\n",
      "Training Iteration 3000 of epoch 12 complete. Loss: 4.736380577087402; Acc:0.2265625; Time taken (s): 0.8018078804016113\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.4045257568359375; Mean Acc:0.17578125; Time taken (s): 0.43532562255859375\n",
      "Dev Iteration 500 complete. Mean Loss: 5.501474566088465; Mean Acc:0.1580042988061905; Time taken (s): 0.4442143440246582\n",
      "Epoch 12 complete! Development Accuracy: 0.1574697494506836; Development Loss: 5.511544129427741\n",
      "\n",
      "--- Training model Epoch: 14 ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Iteration 0 of epoch 13 complete. Loss: 5.162001132965088; Acc:0.16015625; Time taken (s): 0.43438196182250977\n",
      "Training Iteration 500 of epoch 13 complete. Loss: 4.908546447753906; Acc:0.1875; Time taken (s): 0.8007111549377441\n",
      "Training Iteration 1000 of epoch 13 complete. Loss: 4.8617753982543945; Acc:0.23828125; Time taken (s): 0.7831194400787354\n",
      "Training Iteration 1500 of epoch 13 complete. Loss: 5.111323833465576; Acc:0.1484375; Time taken (s): 0.7764487266540527\n",
      "Training Iteration 2000 of epoch 13 complete. Loss: 5.000035285949707; Acc:0.16015625; Time taken (s): 0.7979497909545898\n",
      "Training Iteration 2500 of epoch 13 complete. Loss: 4.8728156089782715; Acc:0.1953125; Time taken (s): 0.8000571727752686\n",
      "Training Iteration 3000 of epoch 13 complete. Loss: 4.711226463317871; Acc:0.234375; Time taken (s): 0.7859194278717041\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.444770812988281; Mean Acc:0.1796875; Time taken (s): 0.4438636302947998\n",
      "Dev Iteration 500 complete. Mean Loss: 5.513881470152956; Mean Acc:0.15713104605674744; Time taken (s): 0.4709594249725342\n",
      "Epoch 13 complete! Development Accuracy: 0.15654872357845306; Development Loss: 5.522985571272233\n",
      "\n",
      "--- Training model Epoch: 15 ---\n",
      "Training Iteration 0 of epoch 14 complete. Loss: 5.120723247528076; Acc:0.1640625; Time taken (s): 0.4377312660217285\n",
      "Training Iteration 500 of epoch 14 complete. Loss: 4.837753772735596; Acc:0.1796875; Time taken (s): 0.8690979480743408\n",
      "Training Iteration 1000 of epoch 14 complete. Loss: 4.853400230407715; Acc:0.23828125; Time taken (s): 0.7932305335998535\n",
      "Training Iteration 1500 of epoch 14 complete. Loss: 5.096338272094727; Acc:0.140625; Time taken (s): 0.7829122543334961\n",
      "Training Iteration 2000 of epoch 14 complete. Loss: 4.997323513031006; Acc:0.15234375; Time taken (s): 0.8041772842407227\n",
      "Training Iteration 2500 of epoch 14 complete. Loss: 4.841213226318359; Acc:0.1796875; Time taken (s): 0.7873742580413818\n",
      "Training Iteration 3000 of epoch 14 complete. Loss: 4.679606914520264; Acc:0.2265625; Time taken (s): 0.7829272747039795\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.469313621520996; Mean Acc:0.1796875; Time taken (s): 0.44514012336730957\n",
      "Dev Iteration 500 complete. Mean Loss: 5.52897876560569; Mean Acc:0.15703748166561127; Time taken (s): 0.4368619918823242\n",
      "Epoch 14 complete! Development Accuracy: 0.1567765772342682; Development Loss: 5.536937126692604\n",
      "\n",
      "--- Training model Epoch: 16 ---\n",
      "Training Iteration 0 of epoch 15 complete. Loss: 5.109157085418701; Acc:0.19921875; Time taken (s): 0.4324026107788086\n",
      "Training Iteration 500 of epoch 15 complete. Loss: 4.820508003234863; Acc:0.1796875; Time taken (s): 0.8206322193145752\n",
      "Training Iteration 1000 of epoch 15 complete. Loss: 4.8652167320251465; Acc:0.24609375; Time taken (s): 0.7752926349639893\n",
      "Training Iteration 1500 of epoch 15 complete. Loss: 5.046000957489014; Acc:0.140625; Time taken (s): 0.8215804100036621\n",
      "Training Iteration 2000 of epoch 15 complete. Loss: 4.947072505950928; Acc:0.15625; Time taken (s): 0.7696115970611572\n",
      "Training Iteration 2500 of epoch 15 complete. Loss: 4.840611457824707; Acc:0.16015625; Time taken (s): 0.80275559425354\n",
      "Training Iteration 3000 of epoch 15 complete. Loss: 4.74587869644165; Acc:0.21875; Time taken (s): 0.7870659828186035\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.447085380554199; Mean Acc:0.17578125; Time taken (s): 0.43015098571777344\n",
      "Dev Iteration 500 complete. Mean Loss: 5.533938719126993; Mean Acc:0.15928299725055695; Time taken (s): 0.4445972442626953\n",
      "Epoch 15 complete! Development Accuracy: 0.15807101130485535; Development Loss: 5.542356180443483\n",
      "\n",
      "--- Training model Epoch: 17 ---\n",
      "Training Iteration 0 of epoch 16 complete. Loss: 5.08898401260376; Acc:0.1796875; Time taken (s): 0.43390345573425293\n",
      "Training Iteration 500 of epoch 16 complete. Loss: 4.839285373687744; Acc:0.19921875; Time taken (s): 0.8405733108520508\n",
      "Training Iteration 1000 of epoch 16 complete. Loss: 4.820333003997803; Acc:0.23828125; Time taken (s): 0.8140842914581299\n",
      "Training Iteration 1500 of epoch 16 complete. Loss: 5.073173522949219; Acc:0.1484375; Time taken (s): 0.7986652851104736\n",
      "Training Iteration 2000 of epoch 16 complete. Loss: 4.946282863616943; Acc:0.15625; Time taken (s): 0.779249906539917\n",
      "Training Iteration 2500 of epoch 16 complete. Loss: 4.871644496917725; Acc:0.1875; Time taken (s): 0.7668900489807129\n",
      "Training Iteration 3000 of epoch 16 complete. Loss: 4.74717378616333; Acc:0.20703125; Time taken (s): 0.7872154712677002\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.448204040527344; Mean Acc:0.1796875; Time taken (s): 0.43377161026000977\n",
      "Dev Iteration 500 complete. Mean Loss: 5.545713028745975; Mean Acc:0.15752089023590088; Time taken (s): 0.4480099678039551\n",
      "Epoch 16 complete! Development Accuracy: 0.15659275650978088; Development Loss: 5.553965585372027\n",
      "\n",
      "--- Training model Epoch: 18 ---\n",
      "Training Iteration 0 of epoch 17 complete. Loss: 5.086112022399902; Acc:0.19140625; Time taken (s): 0.4487617015838623\n",
      "Training Iteration 500 of epoch 17 complete. Loss: 4.849917888641357; Acc:0.203125; Time taken (s): 0.823369026184082\n",
      "Training Iteration 1000 of epoch 17 complete. Loss: 4.795107364654541; Acc:0.25; Time taken (s): 0.8037433624267578\n",
      "Training Iteration 1500 of epoch 17 complete. Loss: 5.033186912536621; Acc:0.14453125; Time taken (s): 0.8010647296905518\n",
      "Training Iteration 2000 of epoch 17 complete. Loss: 4.987819194793701; Acc:0.15234375; Time taken (s): 0.7802653312683105\n",
      "Training Iteration 2500 of epoch 17 complete. Loss: 4.9158830642700195; Acc:0.20703125; Time taken (s): 0.7961597442626953\n",
      "Training Iteration 3000 of epoch 17 complete. Loss: 4.760371208190918; Acc:0.203125; Time taken (s): 0.791724681854248\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.442996978759766; Mean Acc:0.16796875; Time taken (s): 0.4488816261291504\n",
      "Dev Iteration 500 complete. Mean Loss: 5.55215965678354; Mean Acc:0.15716223418712616; Time taken (s): 0.43212056159973145\n",
      "Epoch 17 complete! Development Accuracy: 0.1571250855922699; Development Loss: 5.560463025289423\n",
      "\n",
      "--- Training model Epoch: 19 ---\n",
      "Training Iteration 0 of epoch 18 complete. Loss: 5.071683883666992; Acc:0.1953125; Time taken (s): 0.4387199878692627\n",
      "Training Iteration 500 of epoch 18 complete. Loss: 4.8949055671691895; Acc:0.18359375; Time taken (s): 0.8253841400146484\n",
      "Training Iteration 1000 of epoch 18 complete. Loss: 4.734857082366943; Acc:0.25; Time taken (s): 0.7946341037750244\n",
      "Training Iteration 1500 of epoch 18 complete. Loss: 4.993868350982666; Acc:0.15234375; Time taken (s): 0.8062307834625244\n",
      "Training Iteration 2000 of epoch 18 complete. Loss: 5.005445957183838; Acc:0.15625; Time taken (s): 0.7713487148284912\n",
      "Training Iteration 2500 of epoch 18 complete. Loss: 4.911776065826416; Acc:0.18359375; Time taken (s): 0.7836556434631348\n",
      "Training Iteration 3000 of epoch 18 complete. Loss: 4.721453666687012; Acc:0.21484375; Time taken (s): 0.7883052825927734\n",
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.422239303588867; Mean Acc:0.171875; Time taken (s): 0.4268362522125244\n",
      "Dev Iteration 500 complete. Mean Loss: 5.569257848515006; Mean Acc:0.15711545944213867; Time taken (s): 0.4465329647064209\n",
      "Epoch 18 complete! Development Accuracy: 0.15623658895492554; Development Loss: 5.577315012146445\n",
      "\n",
      "--- Training model Epoch: 20 ---\n",
      "Training Iteration 0 of epoch 19 complete. Loss: 5.0839948654174805; Acc:0.1796875; Time taken (s): 0.44238710403442383\n",
      "Training Iteration 500 of epoch 19 complete. Loss: 4.8574066162109375; Acc:0.1953125; Time taken (s): 0.8411643505096436\n",
      "Training Iteration 1000 of epoch 19 complete. Loss: 4.699411869049072; Acc:0.2421875; Time taken (s): 0.8658132553100586\n",
      "Training Iteration 1500 of epoch 19 complete. Loss: 5.03680419921875; Acc:0.1484375; Time taken (s): 0.7860660552978516\n",
      "Training Iteration 2000 of epoch 19 complete. Loss: 4.986172199249268; Acc:0.15625; Time taken (s): 0.8215997219085693\n",
      "Training Iteration 2500 of epoch 19 complete. Loss: 4.877508163452148; Acc:0.1875; Time taken (s): 0.7871079444885254\n",
      "Training Iteration 3000 of epoch 19 complete. Loss: 4.713963985443115; Acc:0.21875; Time taken (s): 0.7948529720306396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating model on dev data ---\n",
      "Dev Iteration 0 complete. Mean Loss: 5.420502185821533; Mean Acc:0.16796875; Time taken (s): 0.4417452812194824\n",
      "Dev Iteration 500 complete. Mean Loss: 5.569921283188932; Mean Acc:0.15869823098182678; Time taken (s): 0.427410364151001\n",
      "Epoch 19 complete! Development Accuracy: 0.15790633857250214; Development Loss: 5.5775646665517025\n"
     ]
    }
   ],
   "source": [
    "# Using negative log-likelihood loss\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# create model\n",
    "model = TrigramNNmodel(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE, H)\n",
    "\n",
    "# load it to gpu\n",
    "model.cuda(gpu)\n",
    "\n",
    "# using ADAM optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 2e-3)\n",
    "\n",
    "\n",
    "# ------------------------- TRAIN & SAVE MODEL ------------------------\n",
    "best_acc = 0\n",
    "best_model_path = None\n",
    "for epoch in range(20):\n",
    "    st = time.time()\n",
    "    print(\"\\n--- Training model Epoch: {} ---\".format(epoch+1))\n",
    "    for it, data_tensor in enumerate(train_loader):       \n",
    "        context_tensor = data_tensor[:,0:2]\n",
    "        target_tensor = data_tensor[:,2]\n",
    "\n",
    "        context_tensor, target_tensor = context_tensor.cuda(gpu), target_tensor.cuda(gpu)\n",
    "\n",
    "        # zero out the gradients from the old instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # get log probabilities over next words\n",
    "        log_probs = model(context_tensor)\n",
    "\n",
    "        # calculate current accuracy\n",
    "        acc = get_accuracy_from_log_probs(log_probs, target_tensor)\n",
    "\n",
    "        # compute loss function\n",
    "        loss = loss_function(log_probs, target_tensor)\n",
    "\n",
    "        # backward pass and update gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if it % 500 == 0: \n",
    "            print(\"Training Iteration {} of epoch {} complete. Loss: {}; Acc:{}; Time taken (s): {}\".format(it, epoch, loss.item(), acc, (time.time()-st)))\n",
    "            st = time.time()\n",
    "\n",
    "    print(\"\\n--- Evaluating model on dev data ---\")\n",
    "    dev_acc, dev_loss = evaluate(model, loss_function, dev_loader, gpu)\n",
    "    print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(epoch, dev_acc, dev_loss))\n",
    "    if dev_acc > best_acc:\n",
    "        print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "        best_acc = dev_acc\n",
    "        # set best model path\n",
    "        best_model_path = 'best_model_{}.dat'.format(epoch)\n",
    "        # saving best model\n",
    "        torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "54a66188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('computer', 'keyboard'): 0.008548855781555176, ('cat', 'dog'): -0.07967369258403778, ('dog', 'car'): 0.17890217900276184, ('keyboard', 'cat'): 0.01506723277270794}\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Loading Best Model -------------------\n",
    "best_model = TrigramNNmodel(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE, H)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.cuda(gpu)\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=0)\n",
    "\n",
    "lm_similarities = {}\n",
    "\n",
    "# word pairs to calculate similarity\n",
    "words = {('computer','keyboard'),('cat','dog'),('dog','car'),('keyboard','cat')}\n",
    "\n",
    "# ----------- Calculate LM similarities using cosine similarity ----------\n",
    "for word_pairs in words:\n",
    "    w1 = word_pairs[0]\n",
    "    w2 = word_pairs[1]\n",
    "    words_tensor = torch.LongTensor([get_id_of_word(w1),get_id_of_word(w2)])\n",
    "    words_tensor = words_tensor.cuda(gpu)\n",
    "    # get word embeddings from the best model\n",
    "    words_embeds = best_model.embeddings(words_tensor)\n",
    "    # calculate cosine similarity between word vectors\n",
    "    sim = cos(words_embeds[0],words_embeds[1])\n",
    "    lm_similarities[word_pairs] = sim.item()\n",
    "\n",
    "print(lm_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "af37b084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "# ---------------------- Loading Best Model -------------------\n",
    "best_model = TrigramNNmodel(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE, H)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "best_model.cuda(gpu)\n",
    "\n",
    "# predict word\n",
    "context_tensor = torch.tensor([get_id_of_word('a'), get_id_of_word('lot')])\n",
    "\n",
    "context_tensor = context_tensor.cuda(gpu)\n",
    "\n",
    "# get log probabilities over next words\n",
    "log_probs = best_model(context_tensor)\n",
    "\n",
    "ix = torch.argmax(log_probs)\n",
    "result = id_to_word_mappings[ix.item()]\n",
    "\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
